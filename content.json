{"pages":[{"title":"tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"OCR论文阅读-EP","text":"论文题目《Edit Probability for Scene Text Recognition》论文下载地址 文章简介       该论文发表于2018年，其主要是一种基于ED框架的场景文本识别方法。现有的方法基本优化的都是帧级别的最大似然损失。在训练过程中，当出现对齐混乱时，会使后面的帧都出现错误，这会增大训练代价。也就是说，优化帧级别的最大似然损失减少的是替换错误，而对于插入错误和删除错误，会产生额外的损失。举个例子，假设真实标签为”world”，网络前向预测为”wrld”，那么帧级别的最大似然损失就会有偏差。（这里的帧级别的概念是解码时一个帧代表一个字符。） 方法 编辑距离        编辑距离是常用的文本距离度量方法。其主要思想是一个文本经过多少次基本变换（移位，删除，替换）可以转化成里一个文本。本文将编辑距离引入网络训练中，减少对不齐带来的影响。 注意力机制解码器常用的注意力机制解码器公式如下 $$y_i=softmax(v^Ts_j),\\\\s_j=LSTM(y_j-1,c_j,s_j-1)\\\\c_j=\\sum_{k’^=1}^{|h|}\\alpha_{j,k}h_k,\\\\\\alpha_{j,k}=\\frac{exp(e_{j,k})}{\\sum_{k’=1}^{|h|}exp(e_{j,k})},\\\\e_{j,k}=w^Ttanh(Ws_{j-1}+Vh_k+b)$$其中$s_j$是解码器第j时刻的隐状态，$h_k$是编码器第k时刻的隐状态，$c_j$是编码器注意力加权平均后的context vector。       在这篇文章中，当解码第j个时刻时，解码器还会生成$R_j$和$I_j$，$$R_j=(R_j^C,R_j^I,R_j^D)^T=softmax(W_R^T,s_j),\\\\I_j=softmax(W_I^T,s_j)$$$R_j^C$, $R_j^I$, $R_j^D$分别代表$y_j$正确对齐的概率，缺少一个字符的概率，插入字符的概率。$I_j$是在$R_j^I$的条件下，缺失字符的概率分布。 编辑概率 结果 个人看法","link":"/2020/12/28/OCR%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-EP/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/12/28/hello-world/"}],"tags":[{"name":"OCR","slug":"OCR","link":"/tags/OCR/"},{"name":"seq-to-seq","slug":"seq-to-seq","link":"/tags/seq-to-seq/"},{"name":"学习 尝试","slug":"学习-尝试","link":"/tags/%E5%AD%A6%E4%B9%A0-%E5%B0%9D%E8%AF%95/"}],"categories":[{"name":"OCR识别","slug":"OCR识别","link":"/categories/OCR%E8%AF%86%E5%88%AB/"},{"name":"Hexo","slug":"Hexo","link":"/categories/Hexo/"}]}